{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretability\n",
    "\n",
    "In this notebook we will try to understand our models. The goal is to go beyond machine learning metrics commonly used for evaluation and instead focus on other important aspects (see also `test.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Change these if needed!\n",
    "MODEL_PATH = 'train_results/{}.pickle.dat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Model Interpretability**\n",
    "\n",
    "Boosted decision trees aren't necessarily the most interpretable, but there are a few steps we can take towards a better understanding of what is going on with the models. We can try to gain a better understanding of the model by assessing *global* feature importances as well as inspecting *local* predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Global Feature Importances\n",
    "\n",
    "XGBoost has a build in feature to plot feature importance. The \"F-score\" presented here is basically a measure of how often a feature appears in a tree, and is therefore about as basic a feature importance metric as we can get. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map models to titles\n",
    "TITLES = ['Baseline',\n",
    "         'XGB (N=1)',\n",
    "         'XGB (N=2)',\n",
    "         'XGB (N=7)',\n",
    "         'XGB (N=30)',\n",
    "         'XGB w/ History (N=1)',\n",
    "         'XGB w/ History (N=2)',\n",
    "         'XGB w/ History (N=7)',\n",
    "         'XGB w/ History (N=30)']\n",
    "\n",
    "MODELS =  ['baseline',\n",
    "           '50_50_fail_today',\n",
    "           '50_50_fail_today_or_tomorrow',\n",
    "           '50_50_fail_this_week',\n",
    "           '50_50_fail_this_month',\n",
    "           '50_50_fail_today_history',\n",
    "           '50_50_fail_today_or_tomorrow_history',\n",
    "           '50_50_fail_this_week_history',\n",
    "           '50_50_fail_this_month_history']\n",
    "\n",
    "TITLE_DICT = dict(zip(MODELS, TITLES))\n",
    "\n",
    "def get_model(model, model_path):\n",
    "    \"\"\"\n",
    "    Load a saved model so we can use it for predictions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : string\n",
    "        Name of the model\n",
    "        \n",
    "    model_path : string\n",
    "        Path to the saved model\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    loaded_model : Model\n",
    "        Trained Sklearn/xgboost model used to make predictions\n",
    "    \"\"\"\n",
    "    model_file = model_path.format(model)\n",
    "    loaded_model = pickle.load(open(model_file, \"rb\"))\n",
    "    \n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "def plot_importances(model, save=False):\n",
    "    \"\"\"\n",
    "    Plot feature importances\n",
    "    \"\"\"\n",
    "    loaded_model = get_model(model, MODEL_PATH)\n",
    "    plt.figure(figsize=(11,6))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    xgb.plot_importance(loaded_model, \n",
    "                        ax=ax, \n",
    "                        max_num_features=15, \n",
    "                        height=0.8, \n",
    "                        show_values=False)\n",
    "    if 'history' in model:\n",
    "        labels = [(' ').join(label.get_text().split('_')).title() \n",
    "                  for label in ax.get_yticklabels()]\n",
    "    else:\n",
    "        labels = [(' ').join(label.get_text().split('_')).title()[:-4] \n",
    "                  for label in ax.get_yticklabels()]\n",
    "\n",
    "    ax.set_yticklabels(labels)\n",
    "    title = 'Feature Importance for {}'.format(TITLE_DICT[model])\n",
    "    ax.set_title(title)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    \n",
    "    if save:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importance_{}.png'.format(model))\n",
    "    \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importances('50_50_fail_today_or_tomorrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NOTE:*** Rerun the above cell with the names of different models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above feature importances do not tell us anything about the diretionality with which each feature contributes to the prediction. However, this can be analysed through Shapley values. Shapley values are a concept borrowed from cooperative game theory. In essense, the shapley values correspond to the contribution of each feature (or \"player\") towards pushing the prediction (or \"outcome\") away from the expected value of the model.\n",
    "\n",
    "Shapley values are problematic, as is the entire concept of trying to \"explain\" uninterpretable models. Given that interpretability is probably not a critical requirement for this use case, however, we can still use these tools as long as we take the results with a grain of salt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(bucket, prefix):\n",
    "    \"\"\"\n",
    "    Function to get all test data \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket : str\n",
    "        Name of bucket in gcs\n",
    "       \n",
    "    prefix : str\n",
    "        Prefix for the test data in bucket\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    concatenated_df : DataFrame\n",
    "        A dataframe containing all of the data from the csvs\n",
    "    \"\"\"\n",
    "    # List the relevant files in the bucket\n",
    "    files = ['gs://' + ('/').join(blob.id.split('/')[:-1]) \n",
    "             for blob in storage_client.list_blobs(bucket, \n",
    "                                                   prefix=prefix)]\n",
    "    # Read the files, concatenate them, and sort by date\n",
    "    df_for_each_blob = (pd.read_csv(file) for file in files)\n",
    "    concatenated_df = pd.concat(df_for_each_blob, ignore_index=True).sort_values('date')\n",
    "    # Some drives failed between Jan 1st and Jan 10th, we remove them here\n",
    "    # (This could also just have been done in BQ ahead of time)\n",
    "    already_removed_drives = concatenated_df[(concatenated_df['failure'] == 1) \n",
    "                                             & (concatenated_df['date'] < '2019-01-10')]['serial_number'].values\n",
    "    concatenated_df = concatenated_df[~concatenated_df['serial_number'].isin(already_removed_drives)]\n",
    "    \n",
    "    return concatenated_df\n",
    "\n",
    "class PredictionExplainer():\n",
    "    \"\"\"\n",
    "    Class to explain individual predictions of a machine learning model \n",
    "    by plotting shap values and displaying features used to make a decision\n",
    "    \"\"\"\n",
    "    def __init__(self, test_data, model):\n",
    "        self.test_data = test_data\n",
    "        \n",
    "        self.model_name = model\n",
    "        loaded_model = get_model(self.model_name, MODEL_PATH)\n",
    "        self.model = loaded_model\n",
    "        \n",
    "    def _define_window(self, serial_number, date):\n",
    "        \"\"\"\n",
    "        Define a window of data according to the date for which we'd like to explain\n",
    "        the prediction\n",
    "        \"\"\"\n",
    "        dates = pd.date_range(end=date, periods=10)\n",
    "        dates = [str(date).split(' ')[0] for date in dates]\n",
    "        \n",
    "        return self.test_data[(self.test_data['serial_number'] == serial_number) \n",
    "                              & (test_data['date'].isin(dates))]\n",
    "        \n",
    "    def _get_features(self, window):\n",
    "        \"\"\"\n",
    "        Get features for a window of data\n",
    "        \"\"\"        \n",
    "        feat_cols = [col for col in self.test_data.columns if 'smart' in col]\n",
    "        if 'history' in self.model_name:\n",
    "            aggs = ['last', np.mean, np.var, 'min', 'max']\n",
    "        else:\n",
    "            aggs = ['last']\n",
    "        features = window.groupby('serial_number').agg(['last'])[feat_cols]\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _get_important_features_as_frame(self, window, features, shap_values):\n",
    "        \"\"\"\n",
    "        Get important features according to shap as a dataframe\n",
    "        \"\"\"\n",
    "        idx = np.argsort(abs(shap_values[0]))[-10:]\n",
    "        top_feats = features.columns[idx[::-1]]\n",
    "        frame = features[top_feats]\n",
    "        frame.columns = [('_').join(col) for col in top_feats]\n",
    "        \n",
    "        prediction = self.model.predict(features)\n",
    "        frame['prediction'] = prediction\n",
    "        frame['failure'] = window['failure'].iloc[-1]\n",
    "\n",
    "        return frame\n",
    "        \n",
    "    def explain_prediction(self, serial_number, date, plot=True, display_frame=True):\n",
    "        \"\"\"\n",
    "        Explain the prediction of an ML model for a particular\n",
    "        serial number on a particular date\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        serial_number : str\n",
    "            Name of the hard drive\n",
    "            \n",
    "        date : str\n",
    "            Date of the prediction\n",
    "            \n",
    "        plot : bool\n",
    "            Whether to display a shap summary plot\n",
    "            \n",
    "        display_frame : bool\n",
    "            Whether to display important features as a data frame\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        window = self._define_window(serial_number, date)\n",
    "        features = self._get_features(window)\n",
    "        \n",
    "        explainer_shap = shap.TreeExplainer(self.model)\n",
    "        shap_values = explainer_shap.shap_values(features)\n",
    "        \n",
    "        self.frame = self._get_important_features_as_frame(window, \n",
    "                                                      features, \n",
    "                                                      shap_values)\n",
    "        \n",
    "        if plot:\n",
    "            shap.summary_plot(shap_values, features, max_display=10)\n",
    "        if display_frame:\n",
    "            display(self.frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = get_test_data(<BUCKET>, prefix='hard-drive-failure/test/test') # your bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainer for the 50_50_fail_today model\n",
    "xgb_N1_explainer = PredictionExplainer(test_data, '50_50_fail_today')\n",
    "\n",
    "# Explain individual predictions\n",
    "xgb_N1_explainer.explain_prediction('S301K6TS', '2019-01-10')\n",
    "xgb_N1_explainer.explain_prediction('Z305D6G2', '2019-05-17')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
